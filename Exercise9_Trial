#Code for tutorial 9

# import packages
import numpy
import pandas
from scipy.stats import norm
from scipy.optimize import minimize
from scipy.stats import chi2

# [1] likelihood ratio test to determine which of the three mutations significantly reduced the expression of ponzr1
#load data
ponzr1 = pandas.read_csv("ponzr1.csv",header=0,sep=",")
#Pull out only control and treatment you are interested in
#var1=dataframe.loc[dataframe.col1name.isin([list of vals in column]),:]
M124K=ponzr1.loc[ponzr1.mutation.isin(['WT','M124K']),:]
V456D=ponzr1.loc[ponzr1.mutation.isin(['WT','V456D']),:]
I213N=ponzr1.loc[ponzr1.mutation.isin(['WT','I213N']),:]
#Make new data frame with 'group' column (your x=0 or x=1)
#var2=pandas.DataFrame({'y':var1.col2name, 'x':})
M124KFrame=pandas.DataFrame({'y':M124K.ponzr1Counts,'x':0})
#Designate 'treatment' group as x=1
#var2.loc[var1.col1name=='name of treatment group', 'x']=1
M124KFrame.loc[M124K.mutation=='M124K','x']=1
V456DFrame=pandas.DataFrame({'y':V456D.ponzr1Counts,'x':0})
V456DFrame.loc[V456D.mutation=='V456D','x']=1
I213NFrame=pandas.DataFrame({'y':I213N.ponzr1Counts,'x':0})
I213NFrame.loc[I213N.mutation=='I213N','x']=1
#print(M124KFrame)
#print(V456DFrame)
#print(I213NFrame)

#define function for null model of first mutation
def nllike_null(p_null,obs_null):
    B0_null=p_null[0]
    sigma_null=p_null[1]
    expected_null=B0_null
    nll_null=-1*norm(expected_null,sigma_null).logpdf(obs_null.y).sum()
    return nll_null 
#define function for treatment model 
def nllike_treat(p_treat,obs_treat):
    B0_treat=p_treat[0]
    B1_treat=p_treat[1]
    sigma_treat=p_treat[2]
    expected_treat=B0_treat+B1_treat*obs_treat.x
    nll_treat=-1*norm(expected_treat,sigma_treat).logpdf(obs_treat.y).sum()
    return nll_treat
#Minimize nllike to estimate parameters
#Estimate parameters for mutation M124K 
#Null model 
initialGuess_null=numpy.array([1,1])
fit_null_M124K=minimize(nllike_null,initialGuess_null,method="Nelder-Mead",options={'disp':True},args=M124KFrame) #for first mutation
print("estimated parameters for null model")
print(fit_null_M124K.x)
print("negative log likelihood for null model of M124K")
nll_null_M124K=fit_null_M124K.fun
print(nll_null_M124K) #prints negative log likelihood value for null model of M124K 
#Treatment Model 
initialGuess_treat=numpy.array([1,1,1])
fit_treat_M124K=minimize(nllike_treat,initialGuess_treat,method="Nelder-Mead",options={'disp':True},args=M124KFrame) #for first mutation
print("estimated parameters for treatment model")
print(fit_treat_M124K.x)
print("negative log likelihood for treatment model of M124K")
nll_treat_M124K=fit_treat_M124K.fun
print(nll_treat_M124K) #prints negative log likelihood values

#Likelihood ratio test for mutation M124K
D_M124K=2*(nll_null_M124K-nll_treat_M124K)
print(D_M124K)
p_value_M124K=1-scipy.stats.chi2.cdf(x=D_M124K,df=1)
print("p-value for effect of M124K mutation")
print(p_value_M124K)



# [2] "MmarinumGrowth.csv" estimate the maximum growth rate (umax) and the half-saturation constant (Ks)
    #load data
    Growth = pandas.read_csv("MmarinumGrowth.csv",header=0,sep=",")
    #Make a list of numbers from 0 to max value - 1
        #numpy.arrange(max value)

# [3] "leafDecomp.csv" determine whether we should use a constant rate (d = a), a linear response (d = a +bM) or a hump-shaped response (d = a +bM + cM2)
    #load data
    Decomp = pandas.read_csv("leafDecomp.csv",header=0,sep=",")